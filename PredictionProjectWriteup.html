<h2 id="prediction-assignment-writeup">Prediction Assignment Writeup</h2>

<p>Raman Chandrasekar <br>
May 1, 2016</p>

<h2 id="overall-approach">Overall Approach</h2>

<p>When I tried out some approaches on the training and testing data, I found that pretty much any approach takes times on my 2010 MacBook Pro, even with 8GB of memory. I found the following article by Len Greskiâ€™s article very useful,  primarily in the making the processing parallel: <br>
<a href="https://github.com/lgreski/datasciencectacontent/blob/master/markdown/pml-randomForestPerformance.md">https://github.com/lgreski/datasciencectacontent/blob/master/markdown/pml-randomForestPerformance.md</a> </p>

<p>From previous experience with machine learning, I have become fond of using Random Forest (rf) for prediction.  I thought I would try rf and a few other methods on the training data as supplied, to get a baseline. But it turned out that methods such as boosting failed on the training and/or testing data as supplied.</p>

<p>I was able to get a RF model with the training data using the following method. As recommended in the Greski article, I set up my laptop as a 3-core cluster (leaving 1 core for the OS). I set up traincontrol to do 10-fold cross validation, and set it up to use the cluster defined. I then loaded the training data into a dataframe, and trained the <strong>classe</strong> feature/variable against all other features/variables. It took quite a while but finally ended. I then stopped the cluster. The results from this run are presented in the next section.</p>

<h2 id="results-from-the-baseline-random-forest-training">Results from the baseline Random Forest training</h2>

<p>When I examined the model, I got the following:</p>



<pre class="prettyprint"><code class="language-Random Forest hljs r">
<span class="hljs-number">19622</span> samples
 <span class="hljs-number">159</span> predictor
 <span class="hljs-number">5</span> classes: <span class="hljs-string">'A'</span>, <span class="hljs-string">'B'</span>, <span class="hljs-string">'C'</span>, <span class="hljs-string">'D'</span>, <span class="hljs-string">'E'</span> 

 No pre-processing
 Resampling: Cross-Validated (<span class="hljs-number">10</span> fold) 
 Summary of sample sizes: <span class="hljs-number">365</span>, <span class="hljs-number">365</span>, <span class="hljs-number">366</span>, <span class="hljs-number">367</span>, <span class="hljs-number">365</span>, <span class="hljs-number">366</span>, <span class="hljs-keyword">...</span> 
 Resampling results across tuning parameters:

         mtry  Accuracy   Kappa      Accuracy SD  Kappa SD  
 <span class="hljs-number">2</span>  <span class="hljs-number">0.2684459</span>  <span class="hljs-number">0.0000000</span>  <span class="hljs-number">0.005065499</span>  <span class="hljs-number">0.00000000</span>
 <span class="hljs-number">117</span>  <span class="hljs-number">0.9067042</span>  <span class="hljs-number">0.8819656</span>  <span class="hljs-number">0.048654401</span>  <span class="hljs-number">0.06169690</span>
 <span class="hljs-number">6952</span>  <span class="hljs-number">0.9926829</span>  <span class="hljs-number">0.9907819</span>  <span class="hljs-number">0.011781607</span>  <span class="hljs-number">0.01484254</span></code></pre>

<p>Clearly an Accuracy of 0.993 is very good. In fact it is so good, that we need to worry about possibly over-fitting. The next command gave an idea of how each of the 10-fold cross validation steps performed.  The average of these is the 0.993 accuracy we got earlier.</p>

<pre class="prettyprint"><code class=" hljs bash">fit<span class="hljs-variable">$resample</span>
 Accuracy     Kappa Resample
 <span class="hljs-number">1</span>  <span class="hljs-number">1.0000000</span> <span class="hljs-number">1.0000000</span>   Fold01
 <span class="hljs-number">2</span>  <span class="hljs-number">1.0000000</span> <span class="hljs-number">1.0000000</span>   Fold02
 <span class="hljs-number">3</span>  <span class="hljs-number">0.9756098</span> <span class="hljs-number">0.9692423</span>   Fold05
 <span class="hljs-number">4</span>  <span class="hljs-number">1.0000000</span> <span class="hljs-number">1.0000000</span>   Fold04
 <span class="hljs-number">5</span>  <span class="hljs-number">1.0000000</span> <span class="hljs-number">1.0000000</span>   Fold03
 <span class="hljs-number">6</span>  <span class="hljs-number">1.0000000</span> <span class="hljs-number">1.0000000</span>   Fold06
 <span class="hljs-number">7</span>  <span class="hljs-number">1.0000000</span> <span class="hljs-number">1.0000000</span>   Fold09
 <span class="hljs-number">8</span>  <span class="hljs-number">1.0000000</span> <span class="hljs-number">1.0000000</span>   Fold08
 <span class="hljs-number">9</span>  <span class="hljs-number">0.9756098</span> <span class="hljs-number">0.9692884</span>   Fold07
 <span class="hljs-number">10</span> <span class="hljs-number">0.9756098</span> <span class="hljs-number">0.9692884</span>   Fold10</code></pre>

<p>The next command showed that the prediction did very well except for a small confusion between classes D and E.</p>

<pre class="prettyprint"><code class=" hljs mathematica">confusionMatrix.train(fit)
<span class="hljs-keyword">Cross</span>-Validated (<span class="hljs-number">10</span> fold) Confusion Matrix 

(entries are percentages of table totals)

          Reference
Prediction    A    B    <span class="hljs-keyword">C</span>    <span class="hljs-keyword">D</span>    <span class="hljs-keyword">E</span>
         A <span class="hljs-number">26.8</span>  <span class="hljs-number">0.0</span>  <span class="hljs-number">0.0</span>  <span class="hljs-number">0.0</span>  <span class="hljs-number">0.0</span>
         B  <span class="hljs-number">0.0</span> <span class="hljs-number">19.2</span>  <span class="hljs-number">0.2</span>  <span class="hljs-number">0.0</span>  <span class="hljs-number">0.0</span>
         <span class="hljs-keyword">C</span>  <span class="hljs-number">0.0</span>  <span class="hljs-number">0.2</span> <span class="hljs-number">17.0</span>  <span class="hljs-number">0.0</span>  <span class="hljs-number">0.0</span>
         <span class="hljs-keyword">D</span>  <span class="hljs-number">0.0</span>  <span class="hljs-number">0.0</span>  <span class="hljs-number">0.0</span> <span class="hljs-number">17.0</span>  <span class="hljs-number">0.2</span>
         <span class="hljs-keyword">E</span>  <span class="hljs-number">0.0</span>  <span class="hljs-number">0.0</span>  <span class="hljs-number">0.0</span>  <span class="hljs-number">0.0</span> <span class="hljs-number">19.2</span></code></pre>

<p>However, there were all sorts of errors when I tried to predict using this model, with data errors etc. However, since the accuracy was really high, I decided to stick with this RF approach, but to clean up the data and try again.</p>

<h2 id="cleaning-up-the-data">Cleaning up the data</h2>

<p>On examining the data, it is clear that there are many columns with NA values. I wrote a quick R function to identify columns with over 60% NAs in the training data, and remove these columns from  both the training and testing data. I also decided that user_name and any timestamp data should not be factor in deciding the results. I removed these columns as well. From a total of 160 columns, this took me to 89 columns each, with 19,622 rows for training and 20 for testing. </p>

<p>The training and testing data differ in some respects. The training data has the <strong>classe</strong> column, while the testing data has the <strong>problem_id</strong> column.  I sorted the column names in both the training and testing datasets, and put <strong>classe</strong> and <strong>problem_id</strong> at the end of these respectively. This sorting is more for ease of manual inspection, if required.</p>

<p>I reran RandomForest on this reduced dataset.</p>

<h2 id="results-on-running-randomforest-on-reduced-data">Results on running RandomForest on reduced data</h2>
